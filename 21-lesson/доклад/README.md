---
title: Построение production-ready хранилища данных Такси на базе ClickHouse
subtitle: Курс "ClickHouse для инженеров и архитекторов БД"
author: [Ваше ФИО]
date: [Дата]
---

# Слайд 1: Титульный

## Построение production-ready хранилища данных Такси на базе ClickHouse

### Курс "ClickHouse для инженеров и архитекторов БД"

[Ваше ФИО]  
[Дата]

<!--
Комментарий докладчика:
"Здравствуйте, меня зовут [Ваше имя]. Сегодня я представлю вашему вниманию проект по построению отказоустойчивого и масштабируемого хранилища данных для сервиса такси на основе СУБД ClickHouse."
-->

---

# Слайд 2: Цели и задачи проекта

## Что мы реализовали?

- **Цель:** Создать полнофункциональный прототип аналитического хранилища (Data Warehouse)
- **Изучение:** Сравнение скорости и целостности данных при различных способах загрузки
- **Интеграция:** Оркестрация процессов с помощью Airflow
- **Визуализация:** Построение дашбордов в Superset
- **Production-готовность:** Реализация RBAC, бэкапов и многоуровневого хранения

<!--
Комментарий докладчика:
"Проект был нацелен не на абстрактное изучение, а на решение конкретных инженерных задач. Мы хотели проверить, как ClickHouse справляется с типичными нагрузками в пайплайне данных — от загрузки до визуализации, с обязательным соблюдением production-стандартов."
-->

---

# Слайд 3: Архитектура решения

## Общая схема архитектуры

![Архитектура](./images/architect.png)

<!--
Комментарий докладчика:
"Давайте взглянем на сердце нашей системы. Как видно на схеме, мы реализовали комплексную архитектуру. Данные поступают из разных источников: Kafka для потоковых событий о поездках, PostgreSQL как имитация основной OLTP-системы, а также различные API и файлы. Всеми процессами загрузки и преобразования управляет оркестратор Airflow. Очищенные и преобразованные данные хранятся в кластере ClickHouse, а результаты доступны аналитикам через дашборды в Superset. Важно отметить, что желтым выделена реализованная нами часть."
-->

---

# Слайд 4: Структура баз данных в ClickHouse

## Логическое разделение данных по базам

- `streams`, `raw`, `parsed` – для данных из Kafka
- `dict` – для словарей
- `ext`, `prod` – для внешних источников и OLTP-систем
- `datamart` – денормализованная витрина для аналитиков (`datamart.trips`)
- `dashboard` – для метрик мониторинга

<!--
Комментарий докладчика:
"Вместо того чтобы сваливать все в одну кучу, мы сознательно разделили данные на логические базы. Это лучшая практика. Например, `raw` служит буфером для сырых данных, `parsed` — для очищенных, а `datamart` — это финальная витрина с готовыми для анализа данными. Такое разделение строго регламентирует доступ и упрощает управление данными."
-->

---

# Слайд 5: Загрузка данных: Множество коннекторов

## Интеграция с внешними источниками через Airflow

**Реализованные DAG'и:**

1. **PostgreSQL -> CH:** Имитация выгрузки из prod-БД
2. **REST API -> CH:** Загрузка данных через API
3. **S3 -> CH:** Прямая загрузка файлов (Parquet, CSV)
4. **Kafka -> CH:** Потоковый прием данных

<!--
Комментарий докладчика:
"Одной из ключевых задач была проверка гибкости ClickHouse. Через Airflow мы реализовали пайплайны загрузки из всех ключевых типов источников. Например, для данных из API мы использовали движок ReplacingMergeTree, чтобы избежать сложных обновлений. Это отлично демонстрирует, как связка Airflow + ClickHouse справляется с разнородными данными."
-->

---

# Слайд 6: Безопасность: RBAC и квоты

## Управление доступом и ресурсами

- Система ролей: `bi_r`, `analytic_r`, `data_engineer_r`, `observer_r`
- Политики квот: Лимит на количество ошибок ввода
- **Тест:** Пользователь `student` заблокирован после 6 неверных запросов
- **Тест:** Для пользователя `bi` ограничено время выполнения запроса (5 сек)

<!--
Комментарий докладчика:
"Мы не просто создали таблицы, а настроили систему безопасности, как в реальном проекте. Например, у нас есть роль `bi_r` для BI-системы с правами только на чтение. Мы протестировали квоты: пользователь `student`, который часто ошибается в SQL, был заблокирован системой после нескольких попыток. Это защищает кластер от случайных инцидентов."
-->

---

# Слайд 7: Бэкапы и многоуровневое хранение

## Стратегия резервного копирования и экономия на хранении

- **Хранилище:** MinIO (S3-совместимое)
- **Политика хранения:** `default` (горячий SSD) + `s3_cold` (холодное S3)
- **Бэкапы:** Полные и инкрементальные бэкапы средствами ClickHouse
- **Миграция данных:** Автоматическое перемещение на холодное хранилище по TTL

<!--
Комментарий докладчика:
"Вопрос стоимости хранения критически важен. Мы настроили политику, где свежие данные лежат на быстрых дисках, а старые автоматически перемещаются в дешевое S3-хранилище, экономя до 80% затрат. Через Airflow мы настроили регулярное бэкапирование всего кластера, что позволяет быстро восстановить данные в случае сбоя."
-->

---

# Слайд 8: Мониторинг и логирование

## Наблюдаемость системы

**Инструменты:**

1. **Встроенные дашборды ClickHouse**
2. **Системные таблицы:** `system.session_log`, `system.error_log`
3. **Дашборды в Superset**

<!--
Комментарий докладчика:
"Мониторинг реализован на двух уровнях. Системный: мы используем встроенные дашборды ClickHouse для наблюдения за потреблением ресурсов и системные таблицы, где все логи хранятся прямо в БД, что очень удобно для анализа. И бизнес-уровень — дашборды в Superset, которые мы сейчас посмотрим."
-->

---

# Слайд 9: Визуализация в Apache Superset

## Аналитические дашборды для бизнеса

![Superset Dashboard](./images/superset1.jpg)

<!--
Комментарий докладчика:
"Финальная цель любого DWH — предоставление информации бизнесу. Мы успешно подключили Superset к нашей витрине `datamart.trips`. На дашбордах отображаются ключевые метрики: количество и динамика поездок, средняя стоимость, география заказов. Это позволяет аналитикам и менеджерам принимать решения, не написав ни строчки SQL-кода."
-->

---

# Слайд 10: Итоги и выводы

## Что у нас получилось?

- ✅ Построено полнофункциональное, отказоустойчивое хранилище
- ✅ Реализованы все основные каналы загрузки данных
- ✅ Внедрены механизмы безопасности (RBAC) и управления ресурсами
- ✅ Настроена система бэкапов и многоуровневого хранения
- ✅ Реализованы инструменты мониторинга и визуализации

<!--
Комментарий докладчика:
"В результате мы получили не просто учебный пример, а production-ready прототип. Он наглядно демонстрирует, что ClickHouse — это не просто быстрая база данных, а полноценная платформа для построения современного и надежного Data Warehouse."
-->

---

# Слайд 11: Что дальше? Roadmap

## Развитие системы для enterprise-уровня

- **Мониторинг:** Prometheus + Grafana
- **Логи:** Centralized logging (ELK/Loki Stack)
- **Безопасность:** HashiCorp Vault для управления секретами
- **Data Lineage:** Внедрение OpenMetadata или DBT
- **Сложные ETL:** Использование Greenplum/Vertica/Spark

<!--
Комментарий докладчика:
"Для перехода на уровень крупного предприятия архитектуру можно и нужно улучшать. Например, заменить встроенные дашборды на профессиональный стек Prometheus+Grafana, внедрить централизованное хранение логов в ELK и использовать специализированные инструменты вроде DBT для управления трансформациями и линеджем данных."
-->

---

# Слайд 12: Вопросы?

## Спасибо за внимание!

### Вопросы?

<!--
Комментарий докладчика:
"Спасибо за внимание! Я готов ответить на ваши вопросы."
-->

## Как использовать этот шаблон:

1. **Для Markdown-редакторов** (VS Code, Typora):

   - Сохраните как `.md` файл
   - Используйте плагин Markdown Preview Enhanced для просмотра

2. **Для преобразования в PDF/PPTX**:

   - Используйте [pandoc](https://pandoc.org/): `pandoc presentation.md -o presentation.pdf`
   - Или онлайн-конвертеры like [md2pdf](https://www.md2pdf.net/)

3. **Для ручного создания в PowerPoint/Google Slides**:
   - Копируйте содержимое каждого слайда последовательно
   - Комментарии докладчика можно добавить в "Заметки докладчика"
